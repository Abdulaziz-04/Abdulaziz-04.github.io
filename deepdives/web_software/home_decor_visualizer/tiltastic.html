<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Tiltastic – Project Detail</title>
    <link rel="stylesheet" href="../../../assets/css/styles.css" />
  </head>

  <body class="project-detail-page">
    <header class="detail-hero">
      <a class="category-back" href="../../../projects/web-software.html">
        &larr; Back to Projects
      </a>

      <a class="category-pill" href="../../../projects/web-software.html"
        >Web and Software</a
      >

      <h1>Tiltastic – Home Décor Tile Visualizer</h1>

      <p class="detail-summary">
        <b>
          A computer vision powered web application that lets users upload a
          room photo, pick a tile design and instantly preview how different
          floors or walls would look, using monocular depth estimation and floor
          segmentation behind a simple interface.
        </b>
      </p>

      <ul class="detail-meta">
        <li><strong>Timeline:</strong> <b>Jan 2022 to Apr 2022</b></li>
        <li>
          <strong>Tech Stack:</strong>
          <b>React, Flask, Tensorflow, Keras, OpenCV, AWS</b>
        </li>
      </ul>
    </header>

    <main class="section detail-content">
      <!-- HERO IMAGE ABOVE QUICK INSIGHTS -->
      <section class="detail-section detail-hero-gif">
        <figure class="gallery-item gallery-item--medium">
          <img
            src="./images/tiltastic_intro.png"
            alt="Tiltastic main interface with tile options and visualized outputs"
          />
          <figcaption>
            Tiltastic interface for selecting tile designs, rotating the view
            and comparing multiple visualizations side by side.
          </figcaption>
        </figure>
      </section>

      <!-- QUICK INSIGHTS -->
      <section class="detail-section">
        <h2>Quick Insights:</h2>

        <ul class="psr-list">
          <li>
            <strong>Problem:</strong>
            Homeowners and interior clients often rely on catalog photos and
            imagination to choose tiles. It is hard to visualize how a pattern
            will look in their own room and comparing options usually means
            multiple store visits and trial and error.
          </li>
          <br />

          <li>
            <strong>Solution:</strong>
            Built Tiltastic, a web application that takes a room photo and a
            tile design as input, detects floors or walls using a Tensorflow
            based segmentation model and MiDaS depth maps, then overlays the new
            tiles with realistic perspective, lighting and tile count controls.
            The experience feels like trying different tiles directly on the
            user’s own space.
          </li>
          <br />

          <li>
            <strong>Result:</strong>
            Achieved around 85 to 90 percent visually accurate floor and wall
            replacements on test images while keeping the workflow simple:
            upload, choose design, tweak angles and compare variations in a few
            seconds. The same pipeline can extend to paint colors, furniture and
            other interior elements.
          </li>
        </ul>
      </section>

      <!-- INTRODUCTION -->
      <section class="detail-section">
        <h2>Introduction</h2>

        <p>
          Tiltastic was developed during a machine learning internship at
          SoftmaxAI. The goal was to turn tile selection into a visual advisory
          experience that works on any standard room photo. Instead of asking
          users to imagine a final look from catalog images, Tiltastic generates
          a realistic composite of the chosen tiles directly on their own floor
          or wall.
        </p>

        <p>
          The system uses a React based front end that talks to Flask APIs
          hosting trained Tensorflow and Keras models. A floor detection model
          segments the room, MiDaS based monocular depth estimation produces a
          depth map, and OpenCV pipelines handle corner detection, masks and
          pixel level replacement. Results are served back through AWS hosted
          infrastructure so the application can be accessed remotely.
        </p>

        <ul>
          <li>
            Users upload a room image, choose from preset tile designs or custom
            textures and then adjust rotation along X and Z axes plus tile count
            for the final visualization.
          </li>
          <br />
          <li>
            The backend keeps the segmented floor and depth information cached
            per session, reducing repeated visualization time from around
            <b>60 seconds to 30 seconds</b> when trying multiple tile designs on
            the same image.
          </li>
          <br />
          <li>
            The project followed an incremental model: starting from data
            collection and segmentation, then model training, then depth
            mapping, then tile replacement functions, and finally an integrated
            web experience deployed on AWS.
          </li>
        </ul>
      </section>

      <!-- SYSTEM DESIGN -->
      <section class="detail-section detail-gallery">
        <h2>Flow Diagram</h2>

        <div class="gallery-row gallery-row--one">
          <figure
            class="gallery-item gallery-item--clickable gallery-item--wide"
            style="max-width: 1400px"
          >
            <a href="./images/system_design.png" target="_blank">
              <img
                src="./images/system_design.png"
                alt="High level system design of Tiltastic"
                style="width: 100%; height: auto"
              />
            </a>
            <figcaption>
              High level flow: user inputs are processed by Flask APIs that call
              the floor detection model, MiDaS depth estimation and tile
              swapping functions, then return the visualized result.
            </figcaption>
          </figure>
        </div>
      </section>

      <!-- DEMONSTRATION -->
      <section class="detail-section detail-gallery">
        <h2>Demonstration</h2>

        <div class="gallery-row gallery-row--two">
          <!-- Upload dialog -->
          <figure
            class="gallery-item gallery-item--clickable gallery-item--wide"
          >
            <a href="./images/upload.png" target="_blank">
              <img
                src="./images/upload.png"
                alt="Upload image modal in Tiltastic"
              />
            </a>
            <figcaption>
              Upload dialog where users provide a floor or room image to
              visualize. Images are validated and sent to the backend for
              segmentation and depth estimation.
            </figcaption>
          </figure>

          <!-- Visualized floor -->
          <figure
            class="gallery-item gallery-item--clickable gallery-item--wide"
          >
            <a href="./images/visual.png" target="_blank">
              <img
                src="./images/visual.png"
                alt="Visualized floor with new tile pattern"
                style="max-width: 70%; margin: 0 auto; display: block"
              />
            </a>
            <figcaption>
              Example output where the model has detected the floor and overlaid
              the selected tile pattern with realistic perspective and
              repetition count.
            </figcaption>
          </figure>
        </div>
      </section>

      <!-- KEY OUTCOMES AND LEARNINGS -->
      <section class="detail-section detail-impact">
        <h2>Key Outcomes and Learnings</h2>

        <p>
          Tiltastic combined computer vision, depth estimation and web
          development into a single, user facing product. It required designing
          a pipeline that is accurate enough for visual decision making while
          remaining responsive in a browser.
        </p>

        <ul>
          <li>
            Reduced manual trial and error by letting users experiment with
            multiple tile designs from home, replacing the need for repeated
            store visits and physical samples for many early decisions.
          </li>
          <br />
          <li>
            Learned how to train and integrate segmentation and depth models
            with Flask APIs, including handling image preprocessing, model
            loading, error cases and response formatting.
          </li>
          <br />
          <li>
            Implemented pixel level replacement and corner estimation using
            depth gradients, which improved alignment for oblique camera angles
            and non rectangular rooms.
          </li>
          <br />
          <li>
            Applied an iterative development process: start with floor only,
            then add wall support, then optimize for repeated design changes on
            the same image.
          </li>
          <br />
          <li>
            Demonstrated that a relatively compact model plus efficient
            preprocessing can provide visually convincing results at around 85
            to 90 percent accuracy on realistic home interior photos.
          </li>
        </ul>
      </section>
    </main>
  </body>
</html>
