<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Full-Stack Search Engine: Crawl, Index, Rank, and Rerank</title>
    <link rel="stylesheet" href="../../../assets/css/styles.css" />
  </head>

  <body class="project-detail-page">
    <header class="detail-hero">
      <a class="category-back" href="../../../projects/backend_systems.html">
        &larr; Back to Projects
      </a>

      <p
        class="category-pill"
        onclick="window.location.href='../../../projects/backend_systems.html'"
      >
        Backend &amp; Distributed Logic
      </p>
      <br />

      <h1>Full-Stack Search Engine: Crawl, Index, Rank, and Rerank</h1>

      <p class="detail-summary">
        <b>
          Built an end-to-end search engine over a nuclear-safety corpus: custom
          crawler, compressed inverted indexes, classic IR ranking
          (TF-IDF/BM25/LM), graph algorithms (PageRank/HITS), vertical search UI
          with manual assessments, learning-to-rank, and ML-powered spam
          filtering.
        </b>
      </p>

      <p class="detail-summary">
        Part of CS 6200 Information Retrieval course at Northeastern: starting
        with baseline ranking, adding compression and proximity search, building
        a focused crawler, applying link analysis, running a vertical search
        assessment interface, experimenting with learning-to-rank, and closing
        with ML-based spam classification.
      </p>

      <ul class="detail-meta">
        <li>
          <strong>Tech Stack:</strong>
          Python, ElasticSearch, NumPy, scikit-learn, pandas, BeautifulSoup,
          multi-threading, custom inverted index storage
        </li>
      </ul>
    </header>

    <main class="section detail-content">
      <!-- HERO IMAGE -->
      <section class="detail-section detail-hero-gif">
        <figure class="gallery-item gallery-item--wide" style="max-width: none">
          <img
            src="./images/high_level.svg"
            alt="System architecture: crawler → indexer → ranker → reranker → UI"
            style="
              display: block;
              margin: 0 auto;
              width: 100%;
              max-width: 100%;
              height: auto;
            "
          />
          <figcaption style="text-align: center">
            High-level System Architecture
          </figcaption>
        </figure>
      </section>

      <!-- QUICK INSIGHTS -->
      <section class="detail-section">
        <h2>Quick insights</h2>
        <ul class="psr-list">
          <li>
            <strong>Goal:</strong>
            Build a demonstrable, end-to-end search stack covering crawling,
            indexing, ranking, evaluation, and ML reranking.
          </li>
          <br />
          <li>
            <strong>A1 – Baseline Ranking:</strong> Implemented TF-IDF,
            Okapi-TF, BM25, and two Language Models (Laplace, Jelinek-Mercer) on
            a stemmed corpus from scratch. <br /><br />
            <b>Key metric:</b> BM25 Mean Average Precision ≈ <b>0.31</b> based
            on trec_eval.
          </li>
          <br />
          <li>
            <strong>A2 – Index Compression &amp; Proximity:</strong> Built
            compressed inverted indexes and positional lists to enable
            phrase/proximity search. <br /><br />
            <b>Key metric:</b> Compressed index size <b>67.4&nbsp;MB</b> (down
            from 187&nbsp;MB).
          </li>
          <br />
          <li>
            <strong>A3 – Focused Crawler:</strong> Multi-threaded Priority-queue
            frontier expanding based on BFS algorithm, keyword hits, and inlink
            counts with full canonicalization and politeness. <br /><br />
            <b>Key metric:</b>
            The topic of crawling was Nuclear accidents covering different
            incidents such as Hiroshima-Nagasaki, Three-mile island, Kshytm
            disaster.
            <br />
            Collected over 160,000 documents with robots.txt compliance and a
            1-second inter-request delay.
          </li>
          <br />
          <li>
            <strong>A4 – Link Analysis:</strong> Computed PageRank and HITS over
            the custom crawled dataset to add authority/hub signals for
            reranking and getting better search results. <br />
            <br />
            <b>Key metric:</b> Convergence verified via
            <b>Shannon-entropy</b> stabilization across iterations.
          </li>
          <br />
          <li>
            <strong>A5 – Vertical Search UI &amp; Labels:</strong> Built an
            assessment interface for nuclear event queries with 3-point
            relevance judgments (0/1/2). <br />
            <br />
            <b>Key metric:</b> Collected <b>graded labels</b> enabling
            trec_eval-style scoring and LTR training.
          </li>
          <br />
          <li>
            <strong>A6 – Learning-to-Rank:</strong> Trained on features from
            five IR models plus document length; evaluated on held-out queries.
            <br />
            <br />
            <b>Key metric:</b> Best test precision <b>0.414</b>.
          </li>
          <br />
          <li>
            <strong>A7 – Spam Classification:</strong> Compared manual lexicon
            features vs full unigrams using Logistic Regression, Decision Tree,
            and Multinomial NB. <br />
            <br />
            <b>Key metric:</b> Highest <b>ROC-AUC</b> with Logistic Regression
            on <b>unigrams</b>.
          </li>
        </ul>
      </section>
      <!-- SYSTEM OVERVIEW (Merged + De-duplicated) -->
      <section class="detail-section detail-overview">
        <h2>System overview</h2>
        <p>
          The system is a full retrieval pipeline built across seven assignments
          starting with traditional ranking models, adding indexing and
          proximity search, introducing a focused crawler with link analysis,
          finishing with a vertical search interface, learning-to-rank, and spam
          filtering. This section consolidates both the system architecture and
          the design choices behind each stage, structured cleanly across its
          five major components.
        </p>

        <!-- CRAWLER -->
        <h3>Crawler</h3>
        <figure class="gallery-item gallery-item--wide">
          <img src="./images/crawler.svg" alt="Focused crawler architecture" />
        </figure>
        <ul>
          <li>
            Multi-threaded Priority-queue frontier combining BFS waves, keyword
            hits, and inlink counts to balance topical breadth with
            authoritative seeds.
          </li>
          <br />
          <li>
            HTML parsing and canonicalization (lowercasing, fragment/port
            stripping, path cleanup) to unify duplicate URLs.
          </li>
          <br />
          <li>
            Politeness handling via robots.txt, 1-second delays, and per-host
            guards.
          </li>
          <br />
          <li>
            Outputs include raw documents, outgoing links, and link graph
            signals used later by PageRank and HITS.
          </li>
        </ul>

        <!-- INDEXER -->
        <h3>Indexer</h3>
        <figure class="gallery-item gallery-item--wide">
          <img
            src="./images/indexer.svg"
            alt="Indexer architecture with standard and positional indexes"
          />
        </figure>
        <ul>
          <li>
            Two indexing strategies: a standard inverted index for
            BM25/TF-IDF/LM and a positional index for phrase and proximity
            search. I tried stemmed indices and unstemmed indices as well.
          </li>
          <br />
          <li>
            Preprocessing pipeline: tokenization, stopword removal, stemming,
            and term statistics for scoring models.
          </li>
          <br />
          <li>
            Compression via delta-encoding + variable-byte reduced stemmed index
            size to about 67.4 MB (from 187 MB).
          </li>
          <br />
          <li>
            Positional data enabled proximity-based ranking boosts used in the
            second-stage retrieval experiments.
          </li>
        </ul>

        <!-- RANKER -->
        <h3>Ranker</h3>
        <figure class="gallery-item gallery-item--wide">
          <img
            src="./images/ranker.svg"
            alt="Ranking stage including BM25, LM, proximity, PageRank/HITS"
          />
        </figure>
        <ul>
          <li>
            First-pass retrieval using BM25, TF-IDF, Okapi TF, and two language
            models (Laplace and Jelinek–Mercer).
          </li>
          <br />
          <li>
            BM25 produced the strongest classical baseline (MAP around 0.31 on
            the stemmed corpus).
          </li>
          <br />
          <li>
            Link analysis (PageRank and HITS) computed on the crawl graph;
            authority/hub signals improved diversity on topical queries.
          </li>
          <br />
          <li>
            Output: top-k candidates enriched with IR scores, link signals,
            document lengths, and optional proximity features.
          </li>
        </ul>

        <!-- RERANKER -->
        <h3>Reranker</h3>
        <figure class="gallery-item gallery-item--wide">
          <img
            src="./images/reranker.svg"
            alt="Learning-to-rank and spam filtering architecture"
          />
        </figure>
        <ul>
          <li>
            Learning-to-rank experiments used combined IR features (BM25,
            TF-IDF, LM scores), link features (PageRank/HITS), and document
            length.
          </li>
          <br />
          <li>
            Best precision reached ≈0.414 on held-out queries after tuning and
            evaluation through the vertical search judgments.
          </li>
          <br />
          <li>
            Spam filtering with unigrams and heuristics compared Logistic
            Regression, Decision Trees, and Multinomial NB. Logistic Regression
            with full unigrams achieved the strongest ROC-AUC.
          </li>
        </ul>

        <!-- SEARCH UI -->
        <h3>Search engine UI</h3>
        <figure class="gallery-item gallery-item--wide">
          <img
            src="./images/ui.svg"
            alt="Search UI for nuclear-accident retrieval"
          />
        </figure>
        <ul>
          <li>
            Vertical search interface allowed labeling results on a 0/1/2
            relevance scale where 0 is the most relevant, feeding a
            trec_eval-like loop for Mean Average Precision (MAP), Precision@K,
            and nDCG (Normalized Discounted Cumulative Gain) analysis.
          </li>
          <br />
          <li>
            Snippets displayed BM25 scores, titles, and highlighted query terms
            to support manual assessments.
          </li>
          <br />
          <li>
            Labeled data powered the learning-to-rank stage, serving as the
            bridge between classical retrieval and machine-learning reranking.
          </li>
        </ul>
      </section>
      <!-- ADDITIONAL RESULTS GALLERY -->
      <section class="detail-section detail-gallery">
        <h2>UI example and Precision-Recall Curve</h2>

        <div class="gallery-row gallery-row--two">
          <figure class="gallery-item">
            <a href="./images/prec_recall_avg.png" target="_blank">
              <img
                src="./images/prec_recall_avg.png"
                alt="Average precision–recall curve across 20 test queries"
              />
            </a>
            <figcaption>
              Precision–recall curve averaged across all 20 evaluation queries.
            </figcaption>
          </figure>

          <figure class="gallery-item">
            <a href="./images/search.png" target="_blank">
              <img
                src="./images/search.png"
                alt="Vertical search UI displaying ranked nuclear query results"
              />
            </a>
            <figcaption>
              Sample vertical search UI showing ranked results for a
              nuclear-related query.
            </figcaption>
          </figure>
        </div>
      </section>

      <!-- SCALING & FUTURE ENHANCEMENTS -->
      <section class="detail-section">
        <h2>Scaling and future enhancements</h2>
        <p>Ready to grow from coursework to production-grade demo.</p>

        <ul>
          <li>
            <b>Sharding &amp; cache:</b>
            Shard the index by domain/time; add postings and query result cache
            (Redis) to reduce P95 latency.
          </li>
          <br />
          <li>
            <b>Reranking depth:</b>
            Introduce XGBoost with expanded features (PageRank, HITS, click
            priors) and cross-validation over query folds.
          </li>
          <br />
          <li>
            <b>Quality signals:</b>
            Add autocomplete with prefix tries, spell correction via k-grams and
            snippet generator with positional windows.
          </li>
          <br />
          <li>
            <b>Deployment:</b>
            Containerize crawler, indexer, API, and UI; use docker-compose for a
            single-node demo; add health checks and telemetry.
          </li>
          <br />
          <li>
            <b>Spam hardening:</b>
            Add character n-grams for obfuscation, URL reputation features, and
            threshold tuning for precision/recall trade-offs.
          </li>
        </ul>
      </section>

      <!-- IMPACT & LEARNINGS -->
      <section class="detail-section detail-impact">
        <h2>Impact and learnings</h2>
        <ul>
          <li>
            <b>IR depth:</b>
            Got the opportunity to design ElasticSearch from scratch and
            hands-on implementation of classic retrieval models, proximity,
            compression, and graph algorithms, understanding when BM25 beats LMs
            and how link signals diversify results.
          </li>
          <br />
          <li>
            <b>Evaluation mindset:</b>
            Built a full relevance loop: manual labels, trec_eval metrics,
            precision tracking, and feature-driven LTR gains.
          </li>
          <br />
          <li>
            <b>ML integration:</b>
            Combined sparse text features with traditional IR scores; compared
            manual heuristics vs. data-driven vocabularies for spam detection.
          </li>
          <br />
          <li>
            <b>Systems thinking:</b>
            From crawling politeness to storage trade-offs, every stage is
            modular and independently testable for clearer scaling paths.
          </li>
        </ul>
      </section>
    </main>
  </body>
</html>
