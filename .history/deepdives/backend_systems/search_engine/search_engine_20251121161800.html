<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Full-Stack Search Engine: Crawl, Index, Rank, and Rerank</title>
    <link rel="stylesheet" href="../../../assets/css/styles.css" />
  </head>

  <body class="project-detail-page">
    <header class="detail-hero">
      <a class="category-back" href="../../../projects/backend_systems.html">
        &larr; Back to Projects
      </a>

      <p
        class="category-pill"
        onclick="window.location.href='../../../projects/backend_systems.html'"
      >
        Backend &amp; Distributed Logic
      </p>
      <br />

      <h1>>Full-Stack Search Engine: Crawl, Index, Rank, and Rerank</h1>

      <p class="detail-summary">
        <b>
          Built an end-to-end vertical search engine over a nuclear-safety
          corpus (Chernobyl, Fukushima, Kyshtym, Three Mile Island) covering
          crawling, compressed inverted indexes, classic IR ranking
          (TF-IDF/BM25/LM), link analysis (PageRank/HITS on wt2g + custom
          crawl), manual assessments, learning-to-rank, and ML spam filtering.
        </b>
      </p>

      <p class="detail-summary">
        Completed a 7-part IR sequence: baseline ranking and trec_eval scoring,
        compression + proximity search, focused crawler, wt2g PageRank/HITS,
        vertical search UI with labels, learning-to-rank, and spam
        classification.
      </p>

      <ul class="detail-meta">
        <li>
          <strong>Tech Stack:</strong>
          Python, ElasticSearch, NumPy, scikit-learn, pandas, BeautifulSoup,
          priority queues, multi-threading, custom inverted index storage
        </li>
        <li>
          <strong>Corpus:</strong>
          Nuclear-accident documents (≈&nbsp;[160,000] documents crawled) + wt2g
          link graph for link analysis benchmarks
        </li>
      </ul>
    </header>

    <main class="section detail-content">
      <!-- HERO IMAGE -->
      <section class="detail-section detail-hero-gif">
        <figure class="gallery-item gallery-item--wide">
          <img
            src="./images/architecture-placeholder.png"
            alt="System architecture: crawler → indexer → ranker → reranker → UI"
            style="display: block; margin: 0 auto; max-width: 95%; height: auto"
          />
          <figcaption style="text-align: center">
            Architecture: focused crawler feeds compressed inverted indexes;
            BM25/TF-IDF for first-pass ranking; PageRank/HITS signals from wt2g
            and custom crawl; LTR and spam classifiers for reranking/filtering.
          </figcaption>
        </figure>
      </section>

      <!-- QUICK INSIGHTS -->
      <section class="detail-section">
        <h2>Quick insights</h2>
        <ul class="psr-list">
          <li>
            <strong>Goal:</strong>
            End-to-end search stack for a nuclear-accident vertical, evaluated
            with trec_eval metrics (AP, P@10/30).
          </li>
          <br />
          <li>
            <strong>Scope:</strong>
            7 builds: baseline BM25/LM with trec_eval (A1), index compression +
            proximity search (A2), focused crawler (A3), wt2g PageRank/HITS
            (A4), vertical search UI + labels (A5), learning-to-rank (A6), and
            spam classifier (A7).
          </li>
          <br />
          <li>
            <strong>Outcome:</strong>
            BM25 AP ≈ 0.31 (stemmed, A1/A2 via trec_eval); compressed index
            67.4&nbsp;MB vs 187&nbsp;MB decompressed (A2); proximity search AP
            0.2313 stemmed (A2); LTR precision up to 0.414 on test queries (A6);
            Logistic Regression on full unigrams led spam ROC-AUC (A7).
          </li>
        </ul>
      </section>

      <!-- SYSTEM OVERVIEW -->
      <section class="detail-section">
        <h2>System overview</h2>
        <p>
          Vertical search for nuclear accidents: crawls authoritative and news
          domains, indexes titles/body/metadata, ranks with BM25/LM, enriches
          with link signals (wt2g + crawl), and evaluates with human relevance
          labels and trec_eval.
        </p>

        <ul>
          <li>
            <b>Retrieval core:</b>
            Okapi TF, TF-IDF, BM25, Laplace LM, Jelinek-Mercer LM, plus ES
            baseline; BM25 led with AP ≈ 0.31 on stemmed corpus (trec_eval).
          </li>
          <br />
          <li>
            <b>Indexing &amp; compression:</b>
            Stemmed + compressed index shrank to 67.4&nbsp;MB (vs 187&nbsp;MB
            decompressed); tracked unstemmed and proximity variants for phrase
            queries.
          </li>
          <br />
          <li>
            <b>Crawling &amp; frontier:</b>
            Priority-queue frontier (BFS wave, keyword hits, inlink counts);
            canonicalization; robots.txt + 1s delay; collected ≈&nbsp;[put
            document count here] pages.
          </li>
          <br />
          <li>
            <b>Link analysis:</b>
            PageRank and HITS on wt2g (web test collection) and on the
            nuclear-accident crawl; wt2g gives reproducible baselines for hub
            and authority behavior.
          </li>
          <br />
          <li>
            <b>Evaluation &amp; LTR:</b>
            Manual labels (0/1/2) on vertical queries, scored with trec_eval
            (AP, P@10/30); learning-to-rank using five IR model scores + doc
            length, peaking at precision 0.414 on test queries.
          </li>
          <br />
          <li>
            <b>Spam classification:</b>
            Manual spam lexicon vs. full unigrams via CountVectorizer; models:
            Logistic Regression (L1), Decision Tree, Multinomial NB; full
            unigram Logistic delivered best ROC-AUC.
          </li>
        </ul>
      </section>

      <!-- RESPONSE EXAMPLES GALLERY -->
      <section class="detail-section detail-gallery">
        <h2>Sample outputs</h2>
        <div class="gallery-row gallery-row--two">
          <figure class="gallery-item">
            <a href="./images/search-results-placeholder.png" target="_blank">
              <img
                src="./images/search-results-placeholder.png"
                alt="Search results list with highlights and BM25 scores"
              />
            </a>
            <figcaption>
              BM25-ranked nuclear-accident results with snippet highlights.
            </figcaption>
          </figure>

          <figure class="gallery-item">
            <a href="./images/index-stats-placeholder.png" target="_blank">
              <img
                src="./images/index-stats-placeholder.png"
                alt="Index size comparison: compressed vs decompressed"
              />
            </a>
            <figcaption>
              Index size: 67.4&nbsp;MB compressed vs. 187&nbsp;MB decompressed
              (stemmed).
            </figcaption>
          </figure>
        </div>

        <div class="gallery-row gallery-row--two">
          <figure class="gallery-item">
            <a href="./images/ltr-placeholder.png" target="_blank">
              <img
                src="./images/ltr-placeholder.png"
                alt="Learning-to-rank precision chart"
              />
            </a>
            <figcaption>
              trec_eval precision curve; best test precision 0.414 (LTR).
            </figcaption>
          </figure>

          <figure class="gallery-item">
            <a href="./images/spam-roc-placeholder.png" target="_blank">
              <img
                src="./images/spam-roc-placeholder.png"
                alt="ROC curve for spam classifier"
              />
            </a>
            <figcaption>
              Spam classifier ROC-AUC: Logistic with full unigrams leads.
            </figcaption>
          </figure>
        </div>
      </section>

      <!-- ARCHITECTURE & DESIGN -->
      <section class="detail-section">
        <h2>Architecture and design choices</h2>
        <p>
          From reproducible benchmarks (wt2g + trec_eval) to vertical relevance:
          efficient storage, solid baselines, link signals, and ML reranking.
        </p>

        <ul>
          <li>
            <b>Index variants:</b>
            Stemmed/unstemmed, compressed/decompressed; proximity lists for
            phrase queries (proximity AP: 0.2313 stemmed vs. 0.1814 unstemmed,
            trec_eval).
          </li>
          <br />
          <li>
            <b>Candidate generation:</b>
            Heap-based top-k; cached doc-length norms; ES analyzers for
            stopwords/stemming consistency.
          </li>
          <br />
          <li>
            <b>Link signals:</b>
            PageRank (entropy convergence) and HITS on wt2g to validate
            algorithms; applied to the vertical crawl to surface hubs (often
            Wikipedia) and authorities (incident reports).
          </li>
          <br />
          <li>
            <b>Assessment loop:</b>
            3-point labels stored as space-separated text; trec_eval computes AP
            and P@k; aligns with TREC evaluation style from A1/A2.
          </li>
          <br />
          <li>
            <b>LTR features:</b>
            TF-IDF, Okapi-TF, BM25, Laplace, JM scores + doc length; per-query
            splits; train avg precision 0.297, test avg 0.269 (trec_eval).
          </li>
          <br />
          <li>
            <b>Spam pipeline:</b>
            Manual spam n-grams vs. full vocab; sparse matrices; Logistic,
            Decision Tree, Multinomial NB; unigrams outperform heuristics,
            showing coverage matters.
          </li>
        </ul>
      </section>

      <!-- EDGE CASES & ROBUSTNESS -->
      <section class="detail-section">
        <h2>Edge cases and robustness</h2>
        <p>Built for correctness on crawl, rank, and evaluate.</p>

        <ul>
          <li>
            <b>Canonicalization &amp; politeness:</b>
            Lowercasing, port stripping, fragment removal, duplicate slash
            cleanup; robots.txt honored; 1s inter-request delay; single-request
            per URL guard.
          </li>
          <br />
          <li>
            <b>Frontier fairness:</b>
            BFS wave + keyword hits + inlinks to avoid topic drift while
            prioritizing authoritative nuclear-accident pages.
          </li>
          <br />
          <li>
            <b>Query parsing:</b>
            Token normalization, length normalization; BM25 for stability on
            sparse queries; LM variants for recall on longer queries.
          </li>
          <br />
          <li>
            <b>Assessment UX:</b>
            Dropdown-enforced labels prevent empties; trec_eval-ready outputs
            keep evaluation reproducible.
          </li>
          <br />
          <li>
            <b>Model checks:</b>
            Tracked under/overfit via trec_eval precision bounds (0.1939–0.414);
            compared manual vs. full-vocab spam features for coverage.
          </li>
        </ul>
      </section>

      <!-- SCALING & FUTURE ENHANCEMENTS -->
      <section class="detail-section">
        <h2>Scaling and future enhancements</h2>
        <p>Ready to move from coursework to production demo.</p>

        <ul>
          <li>
            <b>Sharding &amp; cache:</b>
            Shard by domain/time; Redis for postings and query caches to lower
            P95 latency.
          </li>
          <br />
          <li>
            <b>Reranking depth:</b>
            LambdaMART/XGBoost with added features (PageRank, HITS, click
            priors); cross-validation over query folds.
          </li>
          <br />
          <li>
            <b>Quality signals:</b>
            Autocomplete (prefix tries), spell correction (k-grams), and better
            snippets (positional windows).
          </li>
          <br />
          <li>
            <b>Deployment:</b>
            Containerize crawler, indexer, API, UI; docker-compose for a
            single-node demo; add health checks/telemetry.
          </li>
          <br />
          <li>
            <b>Spam hardening:</b>
            Character n-grams for obfuscation, URL reputation features, and
            threshold tuning for precision/recall.
          </li>
        </ul>
      </section>

      <!-- IMPACT & LEARNINGS -->
      <section class="detail-section detail-impact">
        <h2>Impact and learnings</h2>
        <ul>
          <li>
            <b>IR depth:</b>
            Benchmarked on wt2g and trec_eval, then specialized to a vertical
            corpus; learned when BM25, proximity, and link signals win.
          </li>
          <br />
          <li>
            <b>Evaluation mindset:</b>
            Full loop: crawl → index → rank → label → trec_eval → iterate; AP
            and P@k as primary decision metrics.
          </li>
          <br />
          <li>
            <b>ML integration:</b>
            Blended sparse IR scores with text features for LTR and spam; tested
            manual heuristics versus full-vocab approaches.
          </li>
          <br />
          <li>
            <b>Systems thinking:</b>
            Modular stages (crawler, indexer, ranker, link analysis, LTR,
            spam)—each independently testable and scalable.
          </li>
        </ul>
      </section>
    </main>
  </body>
</html>
